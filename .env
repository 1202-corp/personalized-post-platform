# PostgreSQL database configuration
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=ppp_db
POSTGRES_PORT=10306

# Main Bot - Telegram bot token from @BotFather
TELEGRAM_BOT_TOKEN=8257820477:AAGUzl-MvFBRHU2wvG4TyMpTcoZShXHyeac

# Core API URL (used by main-bot and user-bot)
CORE_API_URL=http://api:8000
API_PORT=10300
REDIS_PORT=10307

# [Obsolete] User-bot (Telethon) removed; replaced by channels-scraper. Leave commented.
# TELEGRAM_API_ID=33171556
# TELEGRAM_API_HASH=39cdbb6e64fde8307a200bf3dc8647d1
# TELEGRAM_SESSION_FILE=sessions/212349567_telethon.session
# TELEGRAM_SESSION_STRING=
USER_BOT_URL=http://channels-scraper:8001
USER_BOT_PORT=8001

# Channels-scraper (web-scraping t.me, no Telethon)
CHANNELS_SCRAPER_PORT=10302
CHANNELS_SCRAPER_POLL_INTERVAL_SEC=90

# MiniApp public URL for Telegram WebApp
MINIAPP_URL=https://miniapp-ppplatform.cloudpub.ru/
MINIAPP_PORT=10303

# ML Service URL (optional, defaults to http://ml-service:8002)
ML_SERVICE_URL=http://ml-service:8002
ML_SERVICE_PORT=10301

# Default training channels (comma-separated usernames)
DEFAULT_TRAINING_CHANNELS=@opportunitiesforyou,@innoads
# Standard number of posts per channel to show at start of training
TRAINING_INITIAL_POSTS_PER_CHANNEL=10
# Max extra posts that can be added due to skips
TRAINING_MAX_EXTRA_FROM_SKIP=7

# Main Bot language settings
# Default language for new users if Telegram language is not supported
DEFAULT_LANGUAGE=en_US
# Comma-separated list of supported locales (e.g., "en_US,ru_RU")
SUPPORTED_LANGUAGES=en_US,ru_RU

# Admin Dashboard
ADMIN_DASHBOARD_PORT=10304
ADMIN_USERNAME=admin
ADMIN_PASSWORD=MrcNxWEY
JWT_SECRET=A9Z7x6hIYt2BDu5nqZ-W9WJziglpcyoechfS-gooiBY
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=1440
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7
VITE_API_URL=http://localhost:10300/api/v1

# Embedding generation settings
# Use local embedding model (true) or cloud API like bothub/OpenAI (false)
USE_LOCAL_EMBEDDINGS=false

# Local embedding model URL (when USE_LOCAL_EMBEDDINGS=true)
# In Docker: use service name (http://ollama:11434/api/embeddings)
# On host machine: use localhost (http://localhost:11434/api/embeddings)
LOCAL_EMBEDDING_MODEL_URL=http://ollama:11434/api/embeddings
LOCAL_EMBEDDING_MODEL=all-minilm
OLLAMA_PORT=10308

# Cloud API settings (when USE_LOCAL_EMBEDDINGS=false)
# Bothub.chat - Russian-friendly OpenAI-compatible API
# Or use OpenAI directly: https://api.openai.com/v1
OPENAI_API_BASE=https://bothub.chat/api/v2/openai/v1
OPENAI_API_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6ImRhN2VmZmNiLTVjNjEtNGUyMC05ODQ4LWQ4NjgzMjAxMmQwOSIsImlzRGV2ZWxvcGVyIjp0cnVlLCJpYXQiOjE3NjkwODc2MDgsImV4cCI6MjA4NDY2MzYwOH0.dCc6axUzdIT-lLa5-h7ZVH2z21ZxMVg5j4XGMNmPAog
EMBEDDING_MODEL=text-embedding-3-small

# Qdrant vector database configuration
# Internal Docker ports are always 6333 (HTTP) and 6334 (gRPC)
# External ports for host access (default: 10309 for HTTP, 10310 for gRPC)
QDRANT_HOST=vector-db-qdrant
QDRANT_EXTERNAL_PORT=10309
QDRANT_EXTERNAL_GRPC_PORT=10310
QDRANT_TIMEOUT=30

# ---- ML Service ----

# Embedding (text length, timeouts, logs)
MAX_TEXT_LENGTH=8000
EMBEDDING_TIMEOUT=60.0
ERROR_TEXT_LIMIT=500

# Recommendations (Qdrant search)
DEFAULT_SCORE_THRESHOLD=0.15

# Taste clusters (user clustering by preference vector)
# Max share of users in one cluster (1.7% => max_size = ceil(N * 0.017)); with small N, max_size=1 => one cluster per user
MAX_CLUSTER_SIZE_RATIO=0.017
TASTE_CLUSTER_SIMILARITY_THRESHOLD=0.4

# K-Means (taste clusters). Обычно не трогать: random_state — воспроизводимость, n_init — качество (10 = дефолт sklearn)
# KMEANS_RANDOM_STATE=42
# KMEANS_N_INIT=10
