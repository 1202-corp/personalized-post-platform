# PostgreSQL database configuration
POSTGRES_USER=ppb_user
POSTGRES_PASSWORD=ppb_secret
POSTGRES_DB=ppb_db
POSTGRES_PORT=10306

# Main Bot - Telegram bot token from @BotFather
TELEGRAM_BOT_TOKEN=your_bot_token_here

# User Bot - Get credentials from https://my.telegram.org
TELEGRAM_API_ID=your_api_id
TELEGRAM_API_HASH=your_api_hash
TELEGRAM_SESSION_STRING=your_session_string
USER_BOT_PORT=10302

# MiniApp public URL for Telegram WebApp
MINIAPP_URL=https://your-domain.com
MINIAPP_PORT=10303

# ML Service URL (optional, defaults to http://ml-service:8002)
ML_SERVICE_URL=http://ml-service:8002
ML_SERVICE_PORT=10301

# Default training channels (comma-separated usernames)
DEFAULT_TRAINING_CHANNELS=@durov,@telegram

# Main Bot default interface language (en_US, ru_RU)
DEFAULT_LANGUAGE=ru_RU

# Embedding generation settings
# Use local embedding model (true) or cloud API like bothub/OpenAI (false)
USE_LOCAL_EMBEDDINGS=false

# Local embedding model URL (when USE_LOCAL_EMBEDDINGS=true)
# In Docker: use service name (http://ollama:11434/api/embeddings)
# On host machine: use localhost (http://localhost:11434/api/embeddings)
LOCAL_EMBEDDING_MODEL_URL=http://ollama:11434/api/embeddings
LOCAL_EMBEDDING_MODEL=all-minilm
OLLAMA_PORT=10308

# Cloud API settings (when USE_LOCAL_EMBEDDINGS=false)
# Bothub.chat - Russian-friendly OpenAI-compatible API
# Or use OpenAI directly: https://api.openai.com/v1
OPENAI_API_BASE=https://bothub.chat/api/v2/openai/v1
OPENAI_API_KEY=your_openai_api_key_here
EMBEDDING_MODEL=text-embedding-ada-002

# Qdrant vector database configuration
QDRANT_HOST=vector-db-qdrant
QDRANT_PORT=10309
QDRANT_GRPC_PORT=10310

# Service ports (external ports, internal are fixed)
API_PORT=10300
ADMIN_DASHBOARD_PORT=10304
REDIS_PORT=10307

