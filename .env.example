# PostgreSQL database configuration
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_postgres_password
POSTGRES_DB=ppp_db
POSTGRES_PORT=10306

# Main Bot - Telegram bot token from @BotFather
TELEGRAM_BOT_TOKEN=your_bot_token_here

# Core API URL (used by main-bot and user-bot)
CORE_API_URL=http://api:8000
API_PORT=10300
REDIS_PORT=10307

# User Bot - Get credentials from https://my.telegram.org
TELEGRAM_API_ID=your_api_id
TELEGRAM_API_HASH=your_api_hash
# Session: use either a .session file path OR a session string (file takes priority if both set)
# For Docker, sessions/ is mounted into container; use path relative to /app, e.g.:
# TELEGRAM_SESSION_FILE=sessions/212349567_telethon.session
# TELEGRAM_SESSION_STRING=your_session_string
TELEGRAM_SESSION_STRING=your_session_string
USER_BOT_URL=http://user-bot:8001
USER_BOT_PORT=10302

# MiniApp public URL for Telegram WebApp
MINIAPP_URL=https://your-domain.com
MINIAPP_PORT=10303

# ML Service URL (optional, defaults to http://ml-service:8002)
ML_SERVICE_URL=http://ml-service:8002
ML_SERVICE_PORT=10301

# Default training channels (comma-separated usernames)
DEFAULT_TRAINING_CHANNELS=@durov,@telegram
# Number of posts to scrape per channel during training
POSTS_PER_CHANNEL=7
# Number of recent posts per channel to consider for training pool
TRAINING_RECENT_POSTS_PER_CHANNEL=50
# Standard number of posts per channel to show at start of training
TRAINING_INITIAL_POSTS_PER_CHANNEL=17
# Base number of posts to show in a single training session
TRAINING_BASE_POSTS_COUNT=20
# Max extra posts that can be added due to dislikes
TRAINING_MAX_EXTRA_FROM_DISLIKE=5
# Max extra posts that can be added due to skips
TRAINING_MAX_EXTRA_FROM_SKIP=7
# Realtime posts (new post for publishing): DB + Redis TTL in minutes
REALTIME_POST_TTL_MINUTES=10
# How often to run cleanup of expired realtime posts (seconds); posts are deleted by time, not by event
REALTIME_POST_CLEANUP_INTERVAL_SECONDS=60

# Main Bot: post content cache TTL (seconds). Training = 6h, realtime = 10 min
CACHE_TTL_SECONDS=21600
REALTIME_CACHE_TTL_SECONDS=600

# Main Bot language settings
# Default language for new users if Telegram language is not supported
DEFAULT_LANGUAGE=en_US
# Comma-separated list of supported locales (e.g., "en_US,ru_RU")
SUPPORTED_LANGUAGES=en_US,ru_RU

# Admin Dashboard
ADMIN_DASHBOARD_PORT=10304
ADMIN_USERNAME=admin
ADMIN_PASSWORD=your_admin_password
JWT_SECRET=your_jwt_secret_key_min_32_chars
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=1440
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7
VITE_API_URL=http://localhost:10300/api/v1

# Embedding generation settings
# Use local embedding model (true) or cloud API like bothub/OpenAI (false)
USE_LOCAL_EMBEDDINGS=false

# Local embedding model URL (when USE_LOCAL_EMBEDDINGS=true)
# In Docker: use service name (http://ollama:11434/api/embeddings)
# On host machine: use localhost (http://localhost:11434/api/embeddings)
LOCAL_EMBEDDING_MODEL_URL=http://ollama:11434/api/embeddings
LOCAL_EMBEDDING_MODEL=all-minilm
OLLAMA_PORT=10308

# Cloud API settings (when USE_LOCAL_EMBEDDINGS=false)
# Bothub.chat - Russian-friendly OpenAI-compatible API
# Or use OpenAI directly: https://api.openai.com/v1
OPENAI_API_BASE=https://bothub.chat/api/v2/openai/v1
OPENAI_API_KEY=your_openai_or_bothub_api_key
EMBEDDING_MODEL=text-embedding-3-small

# Qdrant vector database configuration
# Internal Docker ports are always 6333 (HTTP) and 6334 (gRPC)
# External ports for host access (default: 10309 for HTTP, 10310 for gRPC)
QDRANT_HOST=vector-db-qdrant
QDRANT_EXTERNAL_PORT=10309
QDRANT_EXTERNAL_GRPC_PORT=10310
QDRANT_TIMEOUT=30

# ---- ML Service ----

# Redis (same as API) — ML-service reads post text from cache when building embeddings
REDIS_URL=redis://redis:6379/0
# Core API URL — ML-service fetches post content via API when not in Redis (API may fetch from user-bot)
CORE_API_URL=http://api:8000

# Embedding (text length, timeouts, logs)
MAX_TEXT_LENGTH=8000
EMBEDDING_TIMEOUT=60.0
ERROR_TEXT_LIMIT=500

# Recommendations (Qdrant search)
DEFAULT_SCORE_THRESHOLD=0.3

# Taste clusters (user clustering by preference vector)
# Max share of users in one cluster (1.7% => max_size = ceil(N * 0.017)); with small N, max_size=1 => one cluster per user
MAX_CLUSTER_SIZE_RATIO=0.017
TASTE_CLUSTER_SIMILARITY_THRESHOLD=0.5

# K-Means (taste clusters). Usually leave as default: random_state for reproducibility, n_init for quality (10 = sklearn default)
# KMEANS_RANDOM_STATE=42
# KMEANS_N_INIT=10

# User preference vector (likes/dislikes)
DISLIKE_WEIGHT=0.3

# LLM Reranker
LLM_TIMEOUT=30.0
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=100
COST_PER_1K_INPUT_TOKENS=0.00015
COST_PER_1K_OUTPUT_TOKENS=0.0006

# Database pool
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20
