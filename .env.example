# PostgreSQL database configuration
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_postgres_password
POSTGRES_DB=ppp_db
POSTGRES_PORT=10306

# Main Bot - Telegram bot token from @BotFather
TELEGRAM_BOT_TOKEN=your_bot_token_here

# Core API URL (used by main-bot and user-bot)
CORE_API_URL=http://api:8000
API_PORT=10300
REDIS_PORT=10307

# User Bot - Get credentials from https://my.telegram.org
TELEGRAM_API_ID=your_api_id
TELEGRAM_API_HASH=your_api_hash
TELEGRAM_SESSION_STRING=your_session_string
USER_BOT_URL=http://user-bot:8001
USER_BOT_PORT=10302

# MiniApp public URL for Telegram WebApp
MINIAPP_URL=https://your-domain.com
MINIAPP_PORT=10303

# ML Service URL (optional, defaults to http://ml-service:8002)
ML_SERVICE_URL=http://ml-service:8002
ML_SERVICE_PORT=10301

# Default training channels (comma-separated usernames)
DEFAULT_TRAINING_CHANNELS=@durov,@telegram

# Main Bot language settings
# Default language for new users if Telegram language is not supported
DEFAULT_LANGUAGE=en_US
# Comma-separated list of supported locales (e.g., "en_US,ru_RU")
SUPPORTED_LANGUAGES=en_US,ru_RU

# Admin Dashboard
ADMIN_DASHBOARD_PORT=10304
ADMIN_USERNAME=admin
ADMIN_PASSWORD=your_admin_password
JWT_SECRET=your_jwt_secret_key_min_32_chars
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=1440
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7
VITE_API_URL=http://localhost:10300/api/v1

# Embedding generation settings
# Use local embedding model (true) or cloud API like bothub/OpenAI (false)
USE_LOCAL_EMBEDDINGS=false

# Local embedding model URL (when USE_LOCAL_EMBEDDINGS=true)
# In Docker: use service name (http://ollama:11434/api/embeddings)
# On host machine: use localhost (http://localhost:11434/api/embeddings)
LOCAL_EMBEDDING_MODEL_URL=http://ollama:11434/api/embeddings
LOCAL_EMBEDDING_MODEL=all-minilm
OLLAMA_PORT=10308

# Cloud API settings (when USE_LOCAL_EMBEDDINGS=false)
# Bothub.chat - Russian-friendly OpenAI-compatible API
# Or use OpenAI directly: https://api.openai.com/v1
OPENAI_API_BASE=https://bothub.chat/api/v2/openai/v1
OPENAI_API_KEY=your_openai_or_bothub_api_key
EMBEDDING_MODEL=text-embedding-3-small

# Qdrant vector database configuration
# Internal Docker ports are always 6333 (HTTP) and 6334 (gRPC)
# External ports for host access (default: 10309 for HTTP, 10310 for gRPC)
QDRANT_HOST=vector-db-qdrant
QDRANT_EXTERNAL_PORT=10309
QDRANT_EXTERNAL_GRPC_PORT=10310
QDRANT_TIMEOUT=30

# ---- ML Service ----

# Embedding (text length, timeouts, logs)
MAX_TEXT_LENGTH=8000
EMBEDDING_TIMEOUT=60.0
ERROR_TEXT_LIMIT=500

# Recommendations (Qdrant search)
DEFAULT_SCORE_THRESHOLD=0.3

# Taste clusters (user clustering by preference vector)
# Max share of users in one cluster (1.7% => max_size = ceil(N * 0.017)); with small N, max_size=1 => one cluster per user
MAX_CLUSTER_SIZE_RATIO=0.017
TASTE_CLUSTER_SIMILARITY_THRESHOLD=0.5

# K-Means (taste clusters). Usually leave as default: random_state for reproducibility, n_init for quality (10 = sklearn default)
# KMEANS_RANDOM_STATE=42
# KMEANS_N_INIT=10

# User preference vector (likes/dislikes)
DISLIKE_WEIGHT=0.3

# LLM Reranker
LLM_TIMEOUT=30.0
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=100
COST_PER_1K_INPUT_TOKENS=0.00015
COST_PER_1K_OUTPUT_TOKENS=0.0006

# Database pool
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20
